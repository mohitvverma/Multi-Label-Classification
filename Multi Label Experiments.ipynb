{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:09.476941Z",
     "start_time": "2024-06-29T12:43:09.467054Z"
    }
   },
   "source": [
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:09.543213Z",
     "start_time": "2024-06-29T12:43:09.528813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import AUROC\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
   ],
   "id": "91ddc47812dafc97",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.692704Z",
     "start_time": "2024-06-29T12:43:09.601924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/theartificialguy/NLP-with-Deep-Learning/master/BERT/Multi%20Label%20Text%20Classification%20using%20BERT%20PyTorch/train.csv')\n",
    "df.head(5)"
   ],
   "id": "243d019f754e6164",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.744973Z",
     "start_time": "2024-06-29T12:43:10.697984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['context'] = df['TITLE']+df['ABSTRACT']\n",
    "df.head(2)"
   ],
   "id": "c482cc18285d2b7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ID                                        TITLE  \\\n",
       "0   1  Reconstructing Subject-Specific Effect Maps   \n",
       "1   2           Rotation Invariance Neural Network   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "\n",
       "   Quantitative Finance                                            context  \n",
       "0                     0  Reconstructing Subject-Specific Effect Maps  P...  \n",
       "1                     0  Rotation Invariance Neural Network  Rotation i...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps  P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rotation Invariance Neural Network  Rotation i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.766799Z",
     "start_time": "2024-06-29T12:43:10.747890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dropping the unused columns\n",
    "\n",
    "df.drop(columns = ['TITLE', 'ABSTRACT','ID'], axis=1, inplace=True)"
   ],
   "id": "1774e82e8ef94ece",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.778007Z",
     "start_time": "2024-06-29T12:43:10.772460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rearranging the  columns\n",
    "df = df[['context','Physics','Mathematics','Statistics','Quantitative Biology','Quantitative Finance']]"
   ],
   "id": "6aea782874b5b62b",
   "outputs": [],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.784522Z",
     "start_time": "2024-06-29T12:43:10.779011Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(4)",
   "id": "142b39efd4cf1989",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             context  Physics  Mathematics  \\\n",
       "0  Reconstructing Subject-Specific Effect Maps  P...        0            0   \n",
       "1  Rotation Invariance Neural Network  Rotation i...        0            0   \n",
       "2  Spherical polyharmonics and Poisson kernels fo...        0            1   \n",
       "3  A finite element approximation for the stochas...        0            1   \n",
       "\n",
       "   Statistics  Quantitative Biology  Quantitative Finance  \n",
       "0           0                     0                     0  \n",
       "1           0                     0                     0  \n",
       "2           0                     0                     0  \n",
       "3           0                     0                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps  P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rotation Invariance Neural Network  Rotation i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.795129Z",
     "start_time": "2024-06-29T12:43:10.786927Z"
    }
   },
   "cell_type": "code",
   "source": "df[(df['Physics']==1) & (df['Mathematics']==1) & (df['Statistics']==1)]",
   "id": "28cc08bbd42557d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 context  Physics  \\\n",
       "639    Smallest eigenvalue density for regular or fix...        1   \n",
       "9180   A study of periodograms standardized using tra...        1   \n",
       "9254   Copy the dynamics using a learning machine  Is...        1   \n",
       "11294  Low-dose cryo electron ptychography via non-co...        1   \n",
       "13077  Construction of and efficient sampling from th...        1   \n",
       "15687  An unbiased estimator for the ellipticity from...        1   \n",
       "17231  A geometric approach to non-linear correlation...        1   \n",
       "17676  Structure and Randomness of Continuous-Time Di...        1   \n",
       "20627  Lectures on the mean values of functionals -- ...        1   \n",
       "\n",
       "       Mathematics  Statistics  Quantitative Biology  Quantitative Finance  \n",
       "639              1           1                     0                     0  \n",
       "9180             1           1                     0                     0  \n",
       "9254             1           1                     0                     0  \n",
       "11294            1           1                     0                     0  \n",
       "13077            1           1                     0                     0  \n",
       "15687            1           1                     0                     0  \n",
       "17231            1           1                     0                     0  \n",
       "17676            1           1                     0                     0  \n",
       "20627            1           1                     0                     0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Smallest eigenvalue density for regular or fix...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>A study of periodograms standardized using tra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>Copy the dynamics using a learning machine  Is...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>Low-dose cryo electron ptychography via non-co...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077</th>\n",
       "      <td>Construction of and efficient sampling from th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15687</th>\n",
       "      <td>An unbiased estimator for the ellipticity from...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17231</th>\n",
       "      <td>A geometric approach to non-linear correlation...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17676</th>\n",
       "      <td>Structure and Randomness of Continuous-Time Di...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>Lectures on the mean values of functionals -- ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.947962Z",
     "start_time": "2024-06-29T12:43:10.796897Z"
    }
   },
   "cell_type": "code",
   "source": "train, test = train_test_split(df, test_size=0.2, random_state=42)",
   "id": "51d834ecbfcd253b",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:10.951692Z",
     "start_time": "2024-06-29T12:43:10.948986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Train size shape : {train.shape}\")\n",
    "print(f\"Test Size shape : {test.shape}\")"
   ],
   "id": "e1c117e3c0d3a82d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size shape : (16777, 6)\n",
      "Test Size shape : (4195, 6)\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.807401Z",
     "start_time": "2024-06-29T12:43:10.952785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ],
   "id": "4bb59b76ff56067",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.823179Z",
     "start_time": "2024-06-29T12:43:12.812245Z"
    }
   },
   "cell_type": "code",
   "source": "target_list = df.iloc[:,1:].columns.values.tolist()",
   "id": "9feb1ddd57a9fe57",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.830413Z",
     "start_time": "2024-06-29T12:43:12.824546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Changing the dataset into PyTorch Formats\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.title = df['context']\n",
    "        self.targets = self.df[target_list].values\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = str(self.title[idx])\n",
    "        item = \"\".join(item.split())\n",
    "        \n",
    "        item = self.tokenizer.encode_plus(\n",
    "            text=item,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': item['input_ids'].flatten(),\n",
    "            'attention_mask': item['attention_mask'].flatten(),\n",
    "            'token_type_ids': item['token_type_ids'].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[idx]),\n",
    "        }\n",
    "        "
   ],
   "id": "32ba8f047744a84d",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.849731Z",
     "start_time": "2024-06-29T12:43:12.831499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = train.sample(frac=0.8, random_state = 200).reset_index(drop=True)\n",
    "val_df = train_df.drop(train_df.index).reset_index(drop=True)"
   ],
   "id": "e8acd3407516d194",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.856714Z",
     "start_time": "2024-06-29T12:43:12.851082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 256\n",
    "# CustomDataset will create the data object.\n",
    "\n",
    "train_datasets = CustomDataset(train_df, tokenizer, max_len=max_length)\n",
    "val_datasets = CustomDataset(val_df, tokenizer, max_len=max_length)"
   ],
   "id": "aafbcbf174ed671e",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.860932Z",
     "start_time": "2024-06-29T12:43:12.857922Z"
    }
   },
   "cell_type": "code",
   "source": "train_datasets",
   "id": "ffbf37acf81530",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x393586680>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.864471Z",
     "start_time": "2024-06-29T12:43:12.861851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hyperparameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 1e-05"
   ],
   "id": "6cdff792eed04b39",
   "outputs": [],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.869437Z",
     "start_time": "2024-06-29T12:43:12.865352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data loader\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_datasets, \n",
    "                                               batch_size=TRAIN_BATCH_SIZE, \n",
    "                                               shuffle=True, \n",
    "                                               num_workers=0)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_datasets, \n",
    "                                             batch_size=VALID_BATCH_SIZE,\n",
    "                                             shuffle=False, \n",
    "                                             num_workers=0)"
   ],
   "id": "165c8b8aa55609b6",
   "outputs": [],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.873638Z",
     "start_time": "2024-06-29T12:43:12.870350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps')"
   ],
   "id": "1ae1e78cab8ab979",
   "outputs": [],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:12.879062Z",
     "start_time": "2024-06-29T12:43:12.874891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_ckp(checkpoint_path = None, model= None, optimizer=None):\n",
    "    \"\"\"\n",
    "    Load checkpoint model and optimizer\n",
    "    :param checkpoint_path: path to save checkpoint\n",
    "    :param model: Model which we want to load checkpoint paramters.\n",
    "    :param optimizer: Optimizer which we want defined in previous training loop.\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Load the check-points\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    # Initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    # Initialize optimizer from checkpoint optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "    # Initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    \n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
    "\n",
    "\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    Save checkpoint model and optimizer\n",
    "    :param state: checkpoint we want to save\n",
    "    :param is_best: is this the best checkpoints ; min validation loss\n",
    "    :param checkpoint_path: path to save checkpoint\n",
    "    :param best_model_path: path to save best model\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    torch.save(state, checkpoint_path)\n",
    "    \n",
    "    # If it's a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # Copy that checkpoint file to best file path, best model path\n",
    "        shutil.copyfile(checkpoint_path, best_fpath)"
   ],
   "id": "2899ec7d6aaffdf8",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T12:43:13.881318Z",
     "start_time": "2024-06-29T12:43:12.880761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()   \n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.linear = torch.nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert_model(input_ids, \n",
    "                                  attention_mask=attention_mask, \n",
    "                                  token_type_ids=token_type_ids)\n",
    "        \n",
    "        output_dropout = self.dropout(outputs.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)"
   ],
   "id": "d58ffdced9068c28",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 9.05 GB, other allocations: 688.00 KB, max allowed: 9.07 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[190], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[1;32m     17\u001B[0m model \u001B[38;5;241m=\u001B[39m BERTClass()\n\u001B[0;32m---> 18\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1170\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1171\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1153\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m   1154\u001B[0m             device,\n\u001B[1;32m   1155\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1156\u001B[0m             non_blocking,\n\u001B[1;32m   1157\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[1;32m   1158\u001B[0m         )\n\u001B[0;32m-> 1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 9.05 GB, other allocations: 688.00 KB, max allowed: 9.07 GB). Tried to allocate 89.42 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ],
   "id": "db6f7693e6112c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_targets = []\n",
    "val_outputs = []"
   ],
   "id": "57278b6a6e67b17c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(n_epochs, training_loader, validation_loader, model, optimizer, checkpoint_path, best_model_path):\n",
    "    # Initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        accumulation_steps = 4\n",
    "        model.train()\n",
    "        print('######### EPOCH {}: Training Start #########'.format(epoch))\n",
    "        \n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "            loss = loss_fn(outputs, targets)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print before loss data in training \n",
    "            train_loss = train_loss + ((1/  (batch_idx + 1)) * (loss.item() - train_loss))\n",
    "            \n",
    "            # print after loss data in training\n",
    "        print('######### EPOCH {}: Training End #########'.format(epoch))\n",
    "        print('######### EPOCH {}: Validation Start #########'.format(epoch))\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(validation_loader, 0):\n",
    "                ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "                mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = data['targets'].to(device, dtype=torch.float)\n",
    "                outputs = model(ids, mask, token_type_ids)\n",
    "                \n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss = valid_loss + ((1/ (batch_idx + 1)) * (loss.item() - valid_loss))\n",
    "                val_targets.extend(targets.cpu().detach().numpy()).tolist()\n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "                \n",
    "        print('######### EPOCH {}: Validation End #########'.format(epoch))\n",
    "        train_loss = train_loss / len(validation_loader)\n",
    "        val_loss = val_loss / len(validation_loader)\n",
    "        \n",
    "        print(f'Epoch {val_loss} \\Average Training Loss: {train_loss:.4f} \\Average Validation Loss: {valid_loss:.4f}')\n",
    "        \n",
    "        # Create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        \n",
    "        # save checkpoints\n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        # TODO: save the model if the model decreased\n",
    "        if val_loss <= valid_loss:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}'.format(valid_loss_min, valid_loss))\n",
    "            \n",
    "            # save the best model\n",
    "            print('Saving checkpoint...')\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    print('######### EPOCH {}: Done #########'.format(epoch))\n",
    "    return model"
   ],
   "id": "9f969f84b52d025e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "ckpt_path = os.path.join(os.getcwd(), 'checkpoints')\n",
    "best_model_path = os.path.join(ckpt_path, 'best_model.pth')"
   ],
   "id": "fad6f985b4bc53cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trained_model = train_model(EPOCHS, train_dataloader, val_dataloader, model,optimizer, ckpt_path, best_model_path)",
   "id": "7db7c474947af1c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "78e1e459584cca09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "83c9b2e14761ed86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1d65514ed60deaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c205b2f4aa34de9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
